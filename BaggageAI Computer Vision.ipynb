{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageCms\n",
    "from PIL import ImageFile\n",
    "def overlay_image_alpha(img, img_overlay, x, y, alpha_mask):\n",
    "#Overlay `img_overlay` onto `img` at (x, y) and blend using `alpha_mask`.\n",
    "#`alpha_mask` must have same HxW as `img_overlay` and values in range [0, 1].\n",
    "    # Image ranges\n",
    "    y1, y2 = max(0, y), min(img.shape[0], y + img_overlay.shape[0])\n",
    "    x1, x2 = max(0, x), min(img.shape[1], x + img_overlay.shape[1])\n",
    "\n",
    "    # Overlay ranges\n",
    "    y1o, y2o = max(0, -y), min(img_overlay.shape[0], img.shape[0] - y)\n",
    "    x1o, x2o = max(0, -x), min(img_overlay.shape[1], img.shape[1] - x)\n",
    "\n",
    "    # Exit if nothing to do\n",
    "    if y1 >= y2 or x1 >= x2 or y1o >= y2o or x1o >= x2o:\n",
    "        return\n",
    "\n",
    "    # Blend overlay within the determined ranges\n",
    "    img_crop = img[y1:y2, x1:x2]\n",
    "    img_overlay_crop = img_overlay[y1o:y2o, x1o:x2o]\n",
    "    alpha = alpha_mask[y1o:y2o, x1o:x2o, np.newaxis]\n",
    "    alpha_inv = 1.0 - alpha\n",
    "\n",
    "    img_crop[:] = alpha * img_overlay_crop + alpha_inv * img_crop\n",
    "    \n",
    "# Import Theft Object  \n",
    "# force opening truncated/corrupt image files\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "img = cv2.imread(\"/Users/swathisomayaji/Desktop/BaggageAI_CV_Hiring_Assignment/threat_images/BAGGAGE_20170524_075554_80428_B.jpg\", 1)\n",
    "\n",
    "# PIL image\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "## (1) Convert to gray, and threshold\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "th, threshed = cv2.threshold(gray, 255, 240, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "## (2) Morph-op to remove noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "morphed = cv2.morphologyEx(threshed, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "## (3) Find the max-area contour\n",
    "cnts = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "cnt = sorted(cnts, key=cv2.contourArea)[-1]\n",
    "\n",
    "## (4) Crop\n",
    "x,y,w,h = cv2.boundingRect(cnt)\n",
    "dst = img[y:y+h, x:x+w]\n",
    "# add border/padding around the cropped image\n",
    "dst = cv2.copyMakeBorder(dst, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=[255,255,255])\n",
    "#Creating Object with array interface\n",
    "img = Image.fromarray(dst, 'RGB')\n",
    "#To make the image background transparent, we first need to change \"RGB\" to \"RGBA\".  \n",
    "img = img.convert(\"RGBA\")\n",
    "#Rotate the Image by 45 degree\n",
    "#applying the positive of the angle to anti-rotate clockwise\n",
    "img=img.rotate(45, resample=0, expand=1, center=None, translate=None, fillcolor=None)\n",
    "#Then we first take out the pixel value of this picture and determine whether the pixel is white (255, 255, 255)\n",
    "datas = img.getdata()\n",
    "# Transparency \n",
    "newData = []\n",
    "  \n",
    "for items in datas:\n",
    "    if items[0] == 255 and items[1] == 255 and items[2] == 255:\n",
    "        newData.append((0, 0, 0, 0))\n",
    "    else:\n",
    "        if items[0] >150 and items[1] > 150 and items[2] > 225:\n",
    "            newData.append((0, 0, 0, 0))\n",
    "        else:\n",
    "            newData.append(items)\n",
    "            #print(items)\n",
    "img.putdata(newData)\n",
    "#I replaced all dots with pixel values (255, 255, 255) with transparent\n",
    "#Import Background Image\n",
    "background = Image.open(\"/Users/swathisomayaji/Desktop/BaggageAI_CV_Hiring_Assignment/background_images/S0300542812_20180822020845_L-10_1.jpg\").convert(\"RGBA\")\n",
    "#Find the size of Background image so that size of theft object can be decided. \n",
    "bg_w, bg_h = background.size\n",
    "\n",
    "basewidth = background.size[0]\n",
    "wpercent = (basewidth/float(img.size[0]))\n",
    "hsize = int((float(img.size[1])*float(wpercent)))\n",
    "#Resize of the theft object and assinging it as foreground image.\n",
    "foreground = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "#Find the size of foreground image to \n",
    "img_w, img_h = foreground.size\n",
    "x,y = ( (bg_h - img_h) // 2,(bg_w - img_w) // 2)\n",
    "img = np.array(background)\n",
    "img_overlay_rgba = np.array(foreground)\n",
    "#img should not contain an alpha channel. (e.g. If it is RGBA, convert to RGB first.)\n",
    "#img_overlay has the same number of channels as img.\n",
    "# Perform blending\n",
    "alpha_mask = img_overlay_rgba[:, :, 3] / 255.0\n",
    "img_result = img[:, :, :3].copy()\n",
    "img_overlay = img_overlay_rgba[:, :, :3]\n",
    "overlay_image_alpha(img_result, img_overlay, x, y, alpha_mask*0.7)\n",
    "\n",
    "# Save result\n",
    "Image.fromarray(img_result).save(\"img_result.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
